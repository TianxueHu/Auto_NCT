print(paste('f1',f1))
table(test$Response)
############Model evaluation on themes######
#Randomly shuffle the data
data_train<-data_train[sample(nrow(data_train)),]
##train test split
train<-data_train[1:1613,]
test<-data_train[1614:2017,]
table(test$Response)
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train)
fitted.results <- predict(model,newdata=subset(test,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$Response)
print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test,select=c(6,19,21,22)), type="response") #haydn
pr1 <- prediction(p1, test$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc1
TN<-table(fitted.results,test$Response)[1,1]
FP<-table(fitted.results,test$Response)[1,2]
FN<-table(fitted.results,test$Response)[2,1]
TP<-table(fitted.results,test$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
print(paste('f1',f1))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-data_train[sample(nrow(data_train)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-data_train#[sample(nrow(data_train)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-train#[sample(nrow(data_train)),]
table(train$Response)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-train#[sample(nrow(data_train)),]
table(train$Response)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-train#[sample(nrow(data_train)),]
table(train$Response)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
############Model evaluation on themes######
#Randomly shuffle the data
data_train<-data_train[sample(nrow(data_train)),]
##train test split
train<-data_train[1:1613,]
test<-data_train[1614:2017,]
table(test$Response)
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train)
fitted.results <- predict(model,newdata=subset(test,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test$Response)
print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test,select=c(6,19,21,22)), type="response") #haydn
pr1 <- prediction(p1, test$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc1
TN<-table(fitted.results,test$Response)[1,1]
FP<-table(fitted.results,test$Response)[1,2]
FN<-table(fitted.results,test$Response)[2,1]
TP<-table(fitted.results,test$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
print(paste('f1',f1))
############Model evaluation on themes######
#Randomly shuffle the data
data_train<-data_train[sample(nrow(data_train)),]
##train test split
train<-data_train[1:1613,]
test<-data_train[1614:2017,]
table(test$Response)
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train)
fitted.results <- predict(model,newdata=subset(test,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$Response)
print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test,select=c(6,19,21,22)), type="response") #haydn
pr1 <- prediction(p1, test$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc1
TN<-table(fitted.results,test$Response)[1,1]
FP<-table(fitted.results,test$Response)[1,2]
FN<-table(fitted.results,test$Response)[2,1]
TP<-table(fitted.results,test$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
print(paste('f1',f1))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-train#[sample(nrow(data_train)),]
table(train$Response)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
############Model evaluation on themes######
#Randomly shuffle the data
data_train<-data_train[sample(nrow(data_train)),]
##train test split
train<-data_train[1:1613,]
test<-data_train[1614:2017,]
table(test$Response)
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train)
fitted.results <- predict(model,newdata=subset(test,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$Response)
print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test,select=c(6,19,21,22)), type="response") #haydn
pr1 <- prediction(p1, test$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc1
TN<-table(fitted.results,test$Response)[1,1]
FP<-table(fitted.results,test$Response)[1,2]
FN<-table(fitted.results,test$Response)[2,1]
TP<-table(fitted.results,test$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
print(paste('f1',f1))
########################Perform 10 fold cross validation
#Randomly shuffle the data
data_cv<-train#[sample(nrow(data_train)),]
table(train$Response)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_cv)),breaks=10,labels=FALSE)
acc =list()
ppvlist = list()
recallls= list()
f1ls= list()
AUC=list()
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_cv <- data_cv[testIndexes, ]
train_cv <- data_cv[-testIndexes, ]
# Fitting
model <- glm(Response ~ duration + ArrSkiSteLeap + DepSkiSteLeap + onOffBeat+ArrSkiSteLeap:onOffBeat+DepSkiSteLeap:onOffBeat+DepSkiSteLeap:duration,family=binomial(link='logit'),data=train_cv)
fitted.results <- predict(model,newdata=subset(test_cv,select=c(6,19,21,22)),type='response')
fitted.results <- ifelse(fitted.results > 0.46,1,0)
misClasificError <- mean(fitted.results != test_cv$Response)
table(fitted.results,test_cv$Response)
#print(paste('result',i))
#print(paste('Accuracy',1-misClasificError))
p1 <- predict(model, newdata=subset(test_cv,select=c(6,19,21,22)), type="response")
pr1 <- prediction(p1, test_cv$Response)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
#plot(prf1)
auc1 <- performance(pr1, measure = "auc")
auc1 <- auc1@y.values[[1]]
AUC[i]<-auc1
TN<-table(fitted.results,test_cv$Response)[1,1]
FP<-table(fitted.results,test_cv$Response)[1,2]
FN<-table(fitted.results,test_cv$Response)[2,1]
TP<-table(fitted.results,test_cv$Response)[2,2]
#Precision = TP/TP+FP
PPV<-TP/(TP+FP)
ppvlist[i]<-PPV
#print(paste('PPV',PPV))
#Recall = TP/TP+FN
recall <-TP/(TP+FN)
recallls[i]<-recall
#print(paste('recall',recall))
#f1 score
f1<- 2*(PPV*recall)/PPV+recall
f1ls[i]<-f1
#print(paste('f1',f1))
# Collecting results
acc[i] <- 1-misClasificError
}
mean(unlist(acc))
mean(unlist(ppvlist))
mean(unlist(recallls))
mean(unlist(f1ls))
mean(unlist(AUC))
setwd('/Users/tianxuehu/Documents/MUSI7100/MusicDatasets/TAVERN-update/chordtone_data')
rm(list = ls())
data_test2<-read.csv('HAYDN_Factors.csv',header=TRUE, sep=",")[3:25]
